{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDsVMGiVgSq2"
   },
   "source": [
    "## Переобучение нейронных сетей и борьба с ним\n",
    "\n",
    "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/girafe_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3isBRG6PgSq6"
   },
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "def args_and_kwargs(*args, **kwargs):\n",
    "    return args, kwargs\n",
    "\n",
    "def parse_pytorch_model(model_str):\n",
    "    def parse_layer(layer_str):\n",
    "        layer_name, params = layer_str.split(\"(\", 1)\n",
    "        layer_info = {\"type\": layer_name.strip()}\n",
    "        params_template = layer_str.replace(layer_name, \"args_and_kwargs\")\n",
    "        \n",
    "        param_dict = {}\n",
    "        if len(params):\n",
    "            args, kwargs = eval(params_template)\n",
    "            if len(args) or len(kwargs):\n",
    "                param_dict[\"args\"] = args\n",
    "                for name, value in kwargs.items():\n",
    "                    param_dict[name] = value\n",
    "        layer_info[\"parameters\"] = param_dict\n",
    "        return layer_info\n",
    "\n",
    "    model_dict = {}\n",
    "    lines = model_str.splitlines()\n",
    "    model_name = lines[0].strip(\"()\")\n",
    "    model_dict[\"model_name\"] = model_name\n",
    "    model_dict[\"layers\"] = []\n",
    "\n",
    "    layer_regex = re.compile(r\"\\((\\d+)\\): (.+)\")\n",
    "    for line in lines[1:]:\n",
    "        line = line.strip()\n",
    "        match = layer_regex.match(line)\n",
    "        if match:\n",
    "            index, layer = match.groups()\n",
    "            model_dict[\"layers\"].append({\"index\": int(index), \"layer\": parse_layer(layer)})\n",
    "    return model_dict\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "def get_predictions(model, eval_data, step=10):\n",
    "\n",
    "    predicted_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx in range(0, len(eval_data), step):\n",
    "            y_predicted = model(eval_data[idx : idx + step].to(device))\n",
    "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
    "\n",
    "    predicted_labels = torch.cat(predicted_labels)\n",
    "    predicted_labels = \",\".join([str(x.item()) for x in list(predicted_labels)])\n",
    "    return predicted_labels\n",
    "\n",
    "\n",
    "def get_accuracy(model, data_loader):\n",
    "    predicted_labels = []\n",
    "    real_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            y_predicted = model(batch[0].to(device))\n",
    "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
    "            real_labels.append(batch[1])\n",
    "\n",
    "    predicted_labels = torch.cat(predicted_labels)\n",
    "    real_labels = torch.cat(real_labels)\n",
    "    accuracy_score = (predicted_labels == real_labels).type(torch.FloatTensor).mean()\n",
    "    return accuracy_score\n",
    "\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите файл `hw_overfitting_data_dict.npy` (ссылка есть на странице с заданием), он понадобится для генерации посылок. Код ниже может его загрузить (но в случае возникновения ошибки скачайте и загрузите его вручную).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"wget\" �� ���� ����७��� ��� ���譥�\n",
      "��������, �ᯮ��塞�� �ணࠬ��� ��� ������ 䠩���.\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict -O hw_overfitting_data_dict.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\ML3.0\\hw4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert os.path.exists(\n",
    "    \"D:\\ML3.0\\hw4\\hw_overfitting_data_dict\"\n",
    "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zeA6Q5-CgSq7"
   },
   "source": [
    "### Задача №1 (уже решённая): Создание и обучение модели (Separation)\n",
    "Вы уже решали эту задачу ранее, так что сейчас просто воспроизведите своё решение. Оно понадобится вам в дальнейших шагах.\n",
    "__Ваша первая задача всё та же: реализовать весь пайплан обучения модели и добиться качества $\\geq 88.5\\%$ на тестовой выборке.__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_DEVICE_ID = 0  # change if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "nPG1KbQAgl8b"
   },
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "device = (\n",
    "    torch.device(f\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    ")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 809
    },
    "id": "aYcL28OsgSq8",
    "outputId": "93aafa07-fb56-43bd-f928-918f45fe30e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Image label: 4')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "train_fmnist_data = FashionMNIST(\n",
    "    \".\", train=True, transform=torchvision.transforms.ToTensor(), download=True\n",
    ")\n",
    "test_fmnist_data = FashionMNIST(\n",
    "    \".\", train=False, transform=torchvision.transforms.ToTensor(), download=True\n",
    ")\n",
    "\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_fmnist_data, batch_size=32, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_fmnist_data, batch_size=32, shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "random_batch = next(iter(train_data_loader))\n",
    "_image, _label = random_batch[0][0], random_batch[1][0]\n",
    "plt.figure()\n",
    "plt.imshow(_image.reshape(28, 28))\n",
    "plt.title(f\"Image label: {_label}\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6jWRv1rgSq8"
   },
   "source": [
    "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 88.5% accuracy.\n",
    "\n",
    "__Внимание, ваша модель должна быть представлена именно переменной `model_task_1`. На вход ей должен приходить тензор размерностью (1, 28, 28).__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BcyEFX-RgSq8"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # [batch, 32, 14, 14]\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # [batch, 64, 7, 7]\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "model_task_1 = CNN()\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAoLV4dkoy5M"
   },
   "source": [
    "Не забудьте перенести модель на выбранный `device`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Xas9SIXDoxvZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_task_1.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pLRWysggSq9"
   },
   "source": [
    "Локальные тесты для проверки вашей модели доступны ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_qMQzo1ggSq9",
    "outputId": "c00008eb-ef88-4000-ce47-e8dedd26e061"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything seems fine!\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert model_task_1 is not None, \"Please, use `model_task_1` variable to store your model\"\n",
    "\n",
    "try:\n",
    "    x = random_batch[0].to(device)\n",
    "    y = random_batch[1].to(device)\n",
    "\n",
    "    # compute outputs given inputs, both are variables\n",
    "    y_predicted = model_task_1(x)\n",
    "except Exception as e:\n",
    "    print(\"Something is wrong with the model\")\n",
    "    raise e\n",
    "\n",
    "\n",
    "assert y_predicted.shape[-1] == 10, \"Model should predict 10 logits/probas\"\n",
    "\n",
    "print(\"Everything seems fine!\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "suRmIPwIgSq9"
   },
   "source": [
    "Настройте параметры модели на обучающей выборке. Также рекомендуем поработать с `learning rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "YJnU14bdnZa_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Loss: 0.4754\n",
      "Epoch [2/15], Loss: 0.3161\n",
      "Epoch [3/15], Loss: 0.2664\n",
      "Epoch [4/15], Loss: 0.2377\n",
      "Epoch [5/15], Loss: 0.2108\n",
      "Epoch [6/15], Loss: 0.1908\n",
      "Epoch [7/15], Loss: 0.1742\n",
      "Epoch [8/15], Loss: 0.1594\n",
      "Epoch [9/15], Loss: 0.1455\n",
      "Epoch [10/15], Loss: 0.1309\n",
      "Epoch [11/15], Loss: 0.1223\n",
      "Epoch [12/15], Loss: 0.1122\n",
      "Epoch [13/15], Loss: 0.1036\n",
      "Epoch [14/15], Loss: 0.0958\n",
      "Epoch [15/15], Loss: 0.0885\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "num_epochs = 15\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_task_1.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model_task_1.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in train_data_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_task_1(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_data_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zce7gt1gSq-"
   },
   "source": [
    "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usswrWYOgSq-"
   },
   "source": [
    "Оценим качество классификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Xua3TVZHgSq-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on train set: 0.98298\n"
     ]
    }
   ],
   "source": [
    "train_acc_task_1 = get_accuracy(model_task_1, train_data_loader)\n",
    "print(f\"Neural network accuracy on train set: {train_acc_task_1:3.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "l9KEKXBxgSq-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on test set: 0.9214\n"
     ]
    }
   ],
   "source": [
    "test_acc_task_1 = get_accuracy(model_task_1, test_data_loader)\n",
    "print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4oyhmMobgSq_"
   },
   "source": [
    "Проверка, что необходимые пороги пройдены:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "id": "OAIrURCEgSq_",
    "outputId": "7c983690-a92e-4693-89fb-7c86c002921a"
   },
   "outputs": [],
   "source": [
    "assert test_acc_task_1 >= 0.885, \"Train accuracy is below 0.885 threshold\"\n",
    "assert (\n",
    "    train_acc_task_1 >= 0.905\n",
    "), \"Test accuracy is below 0.905 while test accuracy is fine. We recommend to check your model and data flow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to `submission_dict_task_1.json`\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert os.path.exists(\n",
    "    \"D:\\ML3.0\\hw4\\hw_overfitting_data_dict\"\n",
    "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
    "\n",
    "loaded_data_dict = np.load(\"D:\\ML3.0\\hw4\\hw_overfitting_data_dict\", allow_pickle=True)\n",
    "\n",
    "submission_dict = {\n",
    "    \"train_predictions_task_1\": get_predictions(\n",
    "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
    "    ),\n",
    "    \"test_predictions_task_1\": get_predictions(\n",
    "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
    "    ),\n",
    "    \"model_task_1\": parse_pytorch_model(str(model_task_1)),\n",
    "}\n",
    "\n",
    "with open(\"submission_dict_task_1.json\", \"w\") as iofile:\n",
    "    json.dump(submission_dict, iofile)\n",
    "print(\"File saved to `submission_dict_task_1.json`\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача №2: Переобучение (Initiation)\n",
    "Продолжим работу с набором данных [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). Теперь ваша задача продемонстрировать переобучение модели на обучающей выборке. Достаточно показать, что точность классификации (не только функция потерь!) на тестовой выборке значительно отстает от обучающей.\n",
    "\n",
    "Обращаем ваше внимание, в задаче №3 вам придется починить данную модель (минимизировать эффект переобучения) с помощью механизмов регуляризации, поэтому не переусердствуйте!\n",
    "\n",
    "__Ваша вторая задача: реализовать используя пайплан обучения модели продемонстрировать переобучения модели на обучающей выборке.__\n",
    "\n",
    "Код для обучения модели вы можете переиспользовать. Далее присутствует лишь несколько тестов, которые помогут вам проверить свое решение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращаем внимание, вам необходимо использовать переменную `model_task_2` для хранение модели во второй задаче. \n",
    "\n",
    "Не используйте `Dropout` и `BatchNorm` в этой задаче"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # [batch, 32, 14, 14]\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # [batch, 64, 7, 7]\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "model_task_2 = CNN().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Loss: 0.4269\n",
      "Epoch [2/15], Loss: 0.2720\n",
      "Epoch [3/15], Loss: 0.2255\n",
      "Epoch [4/15], Loss: 0.1906\n",
      "Epoch [5/15], Loss: 0.1666\n",
      "Epoch [6/15], Loss: 0.1426\n",
      "Epoch [7/15], Loss: 0.1198\n",
      "Epoch [8/15], Loss: 0.1036\n",
      "Epoch [9/15], Loss: 0.0866\n",
      "Epoch [10/15], Loss: 0.0738\n",
      "Epoch [11/15], Loss: 0.0623\n",
      "Epoch [12/15], Loss: 0.0543\n",
      "Epoch [13/15], Loss: 0.0480\n",
      "Epoch [14/15], Loss: 0.0420\n",
      "Epoch [15/15], Loss: 0.0357\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "num_epochs = 15\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_task_2.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model_task_2.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in train_data_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_task_2(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_data_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка архитектуры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "layers_task_2 = []\n",
    "for element in parse_pytorch_model(str(model_task_2)).get(\"layers\", []):\n",
    "    layer_name = element[\"layer\"][\"type\"]\n",
    "    assert \"dropout\" not in layer_name.lower(), \"Do not use Dropout in Task 2!\"\n",
    "    assert \"batchnorm\" not in layer_name.lower(), \"Do not use BatchNorm in Task 2!\"\n",
    "    layers_task_2.append(layer_name)\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим качество классификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on train set: 0.98757\n"
     ]
    }
   ],
   "source": [
    "train_acc_task_2 = get_accuracy(model_task_2, train_data_loader)\n",
    "print(f\"Neural network accuracy on train set: {train_acc_task_2:3.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on test set: 0.9165\n"
     ]
    }
   ],
   "source": [
    "test_acc_task_2 = get_accuracy(model_task_2, test_data_loader)\n",
    "print(f\"Neural network accuracy on test set: {test_acc_task_2:3.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_acc_task_2 >= test_acc_task_2, \"Train accuracy must be higher than task accuracy\"\n",
    "assert train_acc_task_2 >= 0.88, \"Train accuracy must be higher than 0.88\"\n",
    "assert (\n",
    "    train_acc_task_2 - test_acc_task_2 >= 0.04\n",
    "), \"Test accuracy should be at least 0.04 lower that train.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_2`.\n",
    "\n",
    "Также предполагается, что в переменной `submission_dict` уже содержатся результаты задачи №1. Если их там нет, загрузите их из сохраненного файла в переменную перед запуском следующей ячейки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to `submission_dict_tasks_1_and_2.json`\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert os.path.exists(\n",
    "    \"D:\\ML3.0\\hw4\\hw_overfitting_data_dict\"\n",
    "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
    "\n",
    "loaded_data_dict = np.load(\"D:\\ML3.0\\hw4\\hw_overfitting_data_dict\", allow_pickle=True)\n",
    "\n",
    "submission_dict.update(\n",
    "    {\n",
    "        \"train_predictions_task_2\": get_predictions(\n",
    "            model_task_2, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
    "        ),\n",
    "        \"test_predictions_task_2\": get_predictions(\n",
    "            model_task_2, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
    "        ),\n",
    "        \"model_task_2\": parse_pytorch_model(str(model_task_2)),\n",
    "    }\n",
    ")\n",
    "\n",
    "with open(\"submission_dict_tasks_1_and_2.json\", \"w\") as iofile:\n",
    "    json.dump(submission_dict, iofile)\n",
    "print(\"File saved to `submission_dict_tasks_1_and_2.json`\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача №3: Исправление модели (Return) \n",
    "Все так же работаем с [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). Наконец, ваша задача исправить ~~ошибки прошлого~~ переобучение модели, построенной в задаче 2. Достаточно добиться расхождения между точностью классификации на обучающей и тестовой выборках не превышающего 0.015 (т.е. полутора процентов).\n",
    "\n",
    "Обращаем ваше внимание, архитектура модели в задаче №3 не должна существенно отличаться от задачи №2! Вы можете использовать Batchnorm, Dropout, уменьшить размерность промежуточных представлений, обратиться к аугментации данных, но вы не можете использовать меньшее количество слоёв.\n",
    "\n",
    "__Ваша третья и финальная задача: исправить модель и/или процесс обучения, дабы справиться с переобучением.__\n",
    "\n",
    "Код для обучения модели вы можете переиспользовать. Далее присутствует лишь несколько тестов, которые помогут вам проверить свое решение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращаем внимание, вам необходимо использовать переменную `model_task_3` для хранение модели во второй задаче. \n",
    "\n",
    "Также код ниже будет обращаться к переменной `layers_task_2`, инициализируйте её, если она не определена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_task_2 = []\n",
    "for element in parse_pytorch_model(str(model_task_2)).get(\"layers\", []):\n",
    "    layer_name = element[\"layer\"][\"type\"]\n",
    "    layers_task_2.append(layer_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert (\n",
    "    layers_task_2 is not None\n",
    "), \"Initializa layers_task_2 vairable which contains list of layers in task 2 model\"\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(32 * 7 * 7, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.conv1(x))        # [batch, 32, 14, 14]\n",
    "        x = self.pool(self.conv2(x))        # [batch, 64, 7, 7]\n",
    "        x = x.view(x.size(0), -1)           # [batch, 3136]\n",
    "        x = self.dropout(F.relu(self.fc1(x)))  # [batch, 128]\n",
    "        x = self.fc2(x)                     # [batch, 10]\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.8578\n",
      "Epoch [2/5], Loss: 0.5330\n",
      "Epoch [3/5], Loss: 0.4489\n",
      "Epoch [4/5], Loss: 0.4059\n",
      "Epoch [5/5], Loss: 0.3748\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "model_task_3 = CNN()\n",
    "model_task_3.to(device)\n",
    "batch_size = 64\n",
    "learning_rate = 0.0015\n",
    "num_epochs = 5\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_task_3.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model_task_3.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in train_data_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_task_3(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_data_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Conv2d', 'BatchNorm2d', 'ReLU', 'Conv2d', 'BatchNorm2d', 'ReLU']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_task_2 = [\n",
    "    \"Conv2d(1, 32, kernel_size=3, padding=1)\",\n",
    "    \"ReLU\",\n",
    "    \"MaxPool2d(kernel_size=2, stride=2)\",\n",
    "    \"Conv2d(32, 64, kernel_size=3, padding=1)\",\n",
    "    \"ReLU\",\n",
    "    \"MaxPool2d(kernel_size=2, stride=2)\",\n",
    "    \"Linear(64 * 7 * 7, 128)\",\n",
    "    \"ReLU\",\n",
    "    \"Linear(128, 10)\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка архитектуры:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим качество классификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on train set: 0.89923\n"
     ]
    }
   ],
   "source": [
    "train_acc_task_3 = get_accuracy(model_task_3, train_data_loader)\n",
    "print(f\"Neural network accuracy on train set: {train_acc_task_3:3.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on test set: 0.8841\n"
     ]
    }
   ],
   "source": [
    "test_acc_task_3 = get_accuracy(model_task_3, test_data_loader)\n",
    "print(f\"Neural network accuracy on test set: {test_acc_task_3:3.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка, что переобучение присутствует:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0113)\n"
     ]
    }
   ],
   "source": [
    "print(train_acc_task_3 - test_acc_task_3)\n",
    "assert train_acc_task_3 >= 0.88, \"Train accuracy must be higher than 0.88\"\n",
    "assert train_acc_task_3 >= 0.865, \"Test accuracy must be higher than 0.865\"\n",
    "assert (\n",
    "    train_acc_task_3 - test_acc_task_3 <= 0.015\n",
    "    \n",
    "), \"Test accuracy should not be lower that train more than by 0.015\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_3`.\n",
    "\n",
    "Также предполагается, что в переменной `submission_dict` уже содержатся результаты задач №1 и №2. Если их там нет, загрузите их из сохраненных файлов перед запуском следующей ячейки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to `submission_dict_final.json`\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert os.path.exists(\n",
    "    \"D:\\ML3.0\\hw4\\hw_overfitting_data_dict\"\n",
    "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
    "\n",
    "loaded_data_dict = np.load(\"D:\\ML3.0\\hw4\\hw_overfitting_data_dict\", allow_pickle=True)\n",
    "\n",
    "submission_dict.update(\n",
    "    {\n",
    "        \"train_predictions_task_3\": get_predictions(\n",
    "            model_task_3, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
    "        ),\n",
    "        \"test_predictions_task_3\": get_predictions(\n",
    "            model_task_3, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
    "        ),\n",
    "        \"model_task_3\": parse_pytorch_model(str(model_task_3)),\n",
    "    }\n",
    ")\n",
    "\n",
    "with open(\"submission_dict_final.json\", \"w\") as iofile:\n",
    "    json.dump(submission_dict, iofile)\n",
    "print(\"File saved to `submission_dict_final.json`\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xai8JL3tgSq_"
   },
   "source": [
    "### Сдача задания\n",
    "Сдайте сгенерированные файлы в соответствующие задачи в соревновании, а именно:\n",
    "* `submission_dict_tasks_1_and_2.json` в задачу Initiation\n",
    "* `submission_dict_final.json` в задачу Return.\n",
    "\n",
    "\n",
    "`submission_dict_task_1.json` сдавать не нужно, он уже был сдан ранее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtWnYAN_gSrA"
   },
   "source": [
    "На этом задание завершено. Поздравляем!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
