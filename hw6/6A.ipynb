{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9Fm9PEVAOJu",
        "outputId": "9de56c7e-9be6-449a-b2e6-f1c1c056f935"
      },
      "outputs": [],
      "source": [
        "import tarfile\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "\n",
        "def extract_tar(tar_filename, extract_path):\n",
        "    with tarfile.open(tar_filename, 'r:gz') as tar:\n",
        "        tar.extractall(path=extract_path)\n",
        "        print(f\"Извлечены файлы в {extract_path}\")\n",
        "\n",
        "def load_filters_from_csv(csv_filename):\n",
        "    return pd.read_csv(csv_filename, header=None).values\n",
        "\n",
        "\n",
        "tar_filename = 'best_pictures.tar.gz'\n",
        "extract_path = 'best_pictures'  \n",
        "\n",
        "extract_tar(tar_filename, extract_path)\n",
        "\n",
        "\n",
        "extracted_files = os.listdir(extract_path)\n",
        "print(\"Извлеченные файлы:\", extracted_files)\n",
        "\n",
        "algos_csv_path = os.path.join(extract_path, 'algos.csv')\n",
        "\n",
        "filters = load_filters_from_csv(algos_csv_path)\n",
        "print(\"Загруженные фильтры:\\n\", filters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJRRLwUsASkO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.ndimage import convolve\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from itertools import permutations\n",
        "import matplotlib.pyplot as plt  \n",
        "\n",
        "\n",
        "filter1 = np.array([[-1.0, -0.5, 0.0],\n",
        "                    [-0.5, 0.5, 0.5],\n",
        "                    [0.0, 0.5, 1.0]])\n",
        "\n",
        "filter2 = np.array([[0.0625, 0.0625, 0.0625],\n",
        "                    [0.0625, 0.0625, 0.0625],\n",
        "                    [0.0625, 0.0625, 0.0625]])\n",
        "\n",
        "\n",
        "unknown_filter = np.array([[ 0.73119182, -0.03341565,  0.0136693 ],\n",
        " [ 0.71254906,  0.48218111, -0.0778814 ],\n",
        " [ 0.67657722,  0.31003467,  0.4760988 ]] )\n",
        "\n",
        "\n",
        "def find_files(directory):\n",
        "\n",
        "    images = {}\n",
        "    outputs = {}\n",
        "\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith('.png'):\n",
        "\n",
        "            number = filename.split('.')[0]\n",
        "            images[number] = os.path.join(directory, filename)\n",
        "        elif filename.endswith('.txt'):\n",
        "     \n",
        "            number = filename.split('.')[0]\n",
        "            outputs[number] = os.path.join(directory, filename)\n",
        "\n",
        "\n",
        "    image_filenames = []\n",
        "    output_filenames = []\n",
        "\n",
        "\n",
        "    for number in sorted(images.keys()):\n",
        "        image_filenames.append(images[number])\n",
        "        if number in outputs:\n",
        "            output_filenames.append(outputs[number])\n",
        "\n",
        "    return image_filenames, output_filenames\n",
        "\n",
        "def load_image_as_2d(image_path):\n",
        "    \"\"\"Загружает изображение как 2D массив (даже если оно цветное)\"\"\"\n",
        "    img = plt.imread(image_path)\n",
        "    if img.ndim == 3:\n",
        "        img = img.mean(axis=2) \n",
        "    return img\n",
        "\n",
        "def load_data(image_filenames, output_filenames):\n",
        "    images = []\n",
        "    expected_outputs = []\n",
        "\n",
        "    for img_file, expected_file in zip(image_filenames, output_filenames):\n",
        "\n",
        "        img = load_image_as_2d(img_file)\n",
        "        images.append(img)\n",
        "\n",
        "        expected_output = np.loadtxt(expected_file)\n",
        "        expected_outputs.append(expected_output)\n",
        "\n",
        "    return images, expected_outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3WCP-NDCWQ_",
        "outputId": "936c9a2b-3f01-4a73-ddde-3adb1166eb7b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "image_filenames, output_filenames = find_files('best_pictures')\n",
        "images, expected_outputs = load_data(image_filenames, output_filenames)\n",
        "\n",
        "images_tensor = torch.tensor(images,dtype=torch.float32)*255  # [N, H, W]\n",
        "targets_tensor = torch.tensor(expected_outputs,dtype=torch.float32) # [N, H_out, W_out]\n",
        "\n",
        "\n",
        "min_val = torch.min(images_tensor)\n",
        "max_val = torch.max(images_tensor)\n",
        "\n",
        "# Нормировка\n",
        "#images_tensor = (images_tensor - min_val) / (max_val - min_val)*255\n",
        "\n",
        "images_tensor = images_tensor.unsqueeze(1)  # [N, 1, H, W]\n",
        "targets_tensor = targets_tensor.unsqueeze(1)  # [N, 1, H_out, W_out]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qd-KMe0JPjhQ",
        "outputId": "d2e31345-fe16-420b-979a-16fdda110f2a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class FullConvModel(nn.Module):\n",
        "    def __init__(self, fixed_filter1, fixed_filter2):\n",
        "        super().__init__()\n",
        "        # (2->3->1)\n",
        "        self.conv2 = nn.Conv2d(1, 1, kernel_size=3, padding=1, bias=False)\n",
        "        self.conv1 = nn.Conv2d(1, 1, kernel_size=3, padding=1, bias=False)\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "            self.conv1.weight.data = torch.tensor(fixed_filter1, dtype=torch.float32).view(1, 1, 3, 3)\n",
        "            self.conv2.weight.data = torch.tensor(fixed_filter2, dtype=torch.float32).view(1, 1, 3, 3)\n",
        "            self.conv1.weight.requires_grad = False\n",
        "            self.conv2.weight.requires_grad = False\n",
        "\n",
        "\n",
        "        self.conv3 = nn.Conv2d(1, 1, kernel_size=3, padding=1, bias=True)\n",
        "        nn.init.normal_(self.conv3.weight, mean=0, std=0.01)\n",
        "        nn.init.zeros_(self.conv3.bias)  \n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv1(x)\n",
        "        return x\n",
        "\n",
        "def train_full_model(model, dataloader, epochs=100, lr=0.001):\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "    criterion = nn.MSELoss()\n",
        "    loss_history = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0.0\n",
        "        for batch_idx, (batch_images, batch_targets) in enumerate(dataloader):\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_images)\n",
        "            loss = criterion(outputs, batch_targets)\n",
        "            loss.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            #if batch_idx % 10 == 0:\n",
        "                #print(f\"Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item():.6f}\")\n",
        "\n",
        "        avg_loss = epoch_loss / len(dataloader)\n",
        "        loss_history.append(avg_loss)\n",
        "        print(f\"Epoch {epoch} завершена. Avg Loss: {avg_loss:.6f}\")\n",
        "\n",
        "    return loss_history\n",
        "\n",
        "\n",
        "dataset = TensorDataset(images_tensor, targets_tensor)\n",
        "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "\n",
        "model = FullConvModel(filter1, filter2)\n",
        "loss_history = train_full_model(model, dataloader, epochs=1000, lr=0.0001)\n",
        "\n",
        "plt.plot(loss_history)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Full Conv Training (Batch)')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"Обученный фильтр 3:\\n\", model.conv3.weight.data.squeeze().cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yO_0LkJJErqY"
      },
      "outputs": [],
      "source": [
        "\n",
        "filters = [\n",
        "    model.conv2.weight.data.squeeze().numpy(),  \n",
        "    model.conv3.weight.data.squeeze().numpy(),  \n",
        "    model.conv1.weight.data.squeeze().numpy() \n",
        "]\n",
        "\n",
        "\n",
        "np.savetxt('reconstructed_algos.csv',\n",
        "           np.vstack([f.flatten() for f in filters]),\n",
        "           delimiter=',', fmt='%.6f')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fWP5k1GlVGL",
        "outputId": "5566fb11-6f16-4b8c-bb10-bfd853a39c02"
      },
      "outputs": [],
      "source": [
        "filters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QHXgPMXBL7V"
      },
      "source": [
        "Дальше можно присмотреться и увидеть, что значения свертки схожи с одной известной нам аналитически сверткой.\n",
        "\n",
        "Методом пристального взора можно понять, что \"верные\" значения это округление этой свертки до 3 знака после запятой"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1i1y9V0bBY5Q"
      },
      "source": [
        "Т.е.:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzEFt-sIBnQK"
      },
      "outputs": [],
      "source": [
        "[[0.12408582, 0.25154385, 0.12425872],\n",
        "[0.2515448 , 0.49695498, 0.251543  ],\n",
        "[0.12426438, 0.25153747, 0.12409208]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvyP6wy8BpTY"
      },
      "source": [
        "-> -> ->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "px2-ogIwBtHv"
      },
      "outputs": [],
      "source": [
        "[[0.125, 0.25, 0.125],\n",
        "[0.25 , 0.5, 0.25  ],\n",
        "[0.125, 0.25, 0.125]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivGG5bt5ByuH"
      },
      "source": [
        "Вот и вся задача. Самое непонятное в ней это умножение/деление на 256 из-за нормировки входных данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X90Q3TKPAjuK"
      },
      "source": [
        "НИЖЕ КОД НЕ ПЕРЕПРОВЕРЯЛСЯ НА КОМПИЛЯЦИЮ!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irpxWS6XAoVP"
      },
      "source": [
        "Для поиска верной последовательности нужно было посмотреть как быстро падает Loss при обучении моделей с разными последовательностями слоёв. Здесь это и происходило в коде"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7U98FfpfG9dO"
      },
      "outputs": [],
      "source": [
        "class FlexibleConvModel(nn.Module):\n",
        "    def __init__(self, filters, order):\n",
        "        super().__init__()\n",
        "        self.order = order\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv2d(1, 1, kernel_size=3, padding=1, bias=False)\n",
        "            for _ in range(3)\n",
        "        ])\n",
        "\n",
        "       \n",
        "        with torch.no_grad():\n",
        "            for i, f in enumerate(filters[:2]):\n",
        "                self.convs[i].weight.data = torch.tensor(f, dtype=torch.float32).view(1, 1, 3, 3)\n",
        "                self.convs[i].weight.requires_grad = False  \n",
        "\n",
        "\n",
        "        nn.init.normal_(self.convs[2].weight, mean=0, std=0.01)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i in self.order:\n",
        "            x = self.convs[i](x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7v_Pb3QMklR"
      },
      "outputs": [],
      "source": [
        "def train_with_order(filters, order, epochs=500, lr=0.0875):\n",
        "    model = FlexibleConvModel(filters, order)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    losses = []\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images_tensor)\n",
        "        loss = criterion(outputs, targets_tensor)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saDxq1YEMk-3",
        "outputId": "c6b9a484-55a1-4cf6-f0c8-9b07f37440d8"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "all_orders = list(itertools.permutations([0, 1, 2]))\n",
        "\n",
        "\n",
        "order_results = {}\n",
        "\n",
        "\n",
        "for order in all_orders:\n",
        "    print(f\"Обучение для порядка: {order}\")\n",
        "    losses = train_with_order([filter1, filter2, None], order)\n",
        "    order_results[order] = losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "Zlh5CGPTMmh0",
        "outputId": "ddb8098e-9dd5-435a-cd13-8aaf142a0536"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "for order, losses in order_results.items():\n",
        "    plt.plot(losses, label=f'Порядок: {order}')\n",
        "\n",
        "plt.xlabel('Эпоха')\n",
        "plt.ylabel('Loss (MSE)')\n",
        "plt.title('Сравнение сходимости для разных порядков фильтров')\n",
        "plt.yscale('log')  \n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTXJBYDkMyO1",
        "outputId": "cdb32bc9-fd4f-4316-9cb2-7cadd3b9c245"
      },
      "outputs": [],
      "source": [
        "for i in order_results:\n",
        "  print(order_results[i][-1])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
